{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "sfL5Jnfr9bWm",
        "outputId": "18b86125-d02f-4e26-bf6c-4a6efeb4fc0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "t4dtacMl9RZj",
        "outputId": "4bedd170-2d90-45fe-9ab6-b843d1c86277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import shutil\n",
        "import sys\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "ENFGhFrg91e3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/my-datasets/yektanet_train.csv\"\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# data Preprocessing\n",
        "def preprocess_data(df):\n",
        "   # Get unique categories\n",
        "    categories = df['category'].unique()\n",
        "\n",
        "    # Create new dataframe with all columns except 'category'\n",
        "    new_df = df.copy()\n",
        "\n",
        "    # Create binary columns for each category\n",
        "    for category in categories:\n",
        "        # Create new column with category name and fill with 0s and 1s\n",
        "        new_df[category] = (df['category'] == category).astype(int)\n",
        "\n",
        "    # Drop the original category column\n",
        "    new_df = new_df.drop('category', axis=1)\n",
        "\n",
        "    return new_df\n",
        "\n",
        "proccessed_data = preprocess_data(data)\n",
        "\n",
        "# get all categories\n",
        "non_category_columns = ['description', 'text_content', 'title']\n",
        "category_columns = [col for col in proccessed_data.columns if col not in non_category_columns]\n",
        "\n",
        "proccessed_data[\"content\"] = proccessed_data['title'] + \"-\" + proccessed_data['text_content'] + \"-\" + proccessed_data['description']\n",
        "\n",
        "\n",
        "# drop useless columns\n",
        "cols_to_drop = [\"title\", \"text_content\",\"description\",\"url\", \"domain\", \"id\",\"h1\",\"h2\"]\n",
        "existing_cols = [col for col in cols_to_drop if col in proccessed_data.columns]\n",
        "proccessed_data.drop(labels=existing_cols, axis=1, inplace=True)\n",
        "\n",
        "proccessed_data.head()\n"
      ],
      "metadata": {
        "id": "iheR7LVh-gd_",
        "outputId": "d5afbd93-c950-4d10-9a50-1cb82fbff028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Ú©ØªØ§Ø¨ Ùˆ Ø§Ø¯Ø¨ÛŒØ§Øª  ØªØ¬Ø§Ø±Øª Ùˆ Ø§Ù‚ØªØµØ§Ø¯  Ø³Ù„Ø§Ù…Øª  ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ùˆ Ú©Ø§Ù…Ù¾Ø¨ÙˆØªØ±  ÙˆØ±Ø²Ø´  \\\n",
              "0              1               0      0                    0     0   \n",
              "1              0               1      0                    0     0   \n",
              "2              0               0      1                    0     0   \n",
              "3              0               0      0                    1     0   \n",
              "4              0               0      0                    1     0   \n",
              "\n",
              "   ØºØ°Ø§ Ùˆ Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ  Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯ÙˆÙ„Øª Ùˆ Ø³ÛŒØ§Ø³Øª  Ù…Ø³Ú©Ù†  Ø®ÙˆØ¯Ø±Ùˆ  Ù…Ø¯ Ùˆ Ø²ÛŒØ¨Ø§ÛŒÛŒ  ...  \\\n",
              "0              0                    0     0      0            0  ...   \n",
              "1              0                    0     0      0            0  ...   \n",
              "2              0                    0     0      0            0  ...   \n",
              "3              0                    0     0      0            0  ...   \n",
              "4              0                    0     0      0            0  ...   \n",
              "\n",
              "   Ø³ÙØ± Ùˆ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ  Ù‡Ù†Ø± Ùˆ Ø³Ø±Ú¯Ø±Ù…ÛŒ  Ø®Ø§Ù†Ù‡ Ùˆ Ø¨Ø§ØºØ¨Ø§Ù†ÛŒ  Ù…ÙˆØ³ÛŒÙ‚ÛŒ  ØªØ­ØµÛŒÙ„Ø§Øª  Ø¹Ù„Ù… Ùˆ Ø¯Ø§Ù†Ø´  \\\n",
              "0              0             0               0       0        0           0   \n",
              "1              0             0               0       0        0           0   \n",
              "2              0             0               0       0        0           0   \n",
              "3              0             0               0       0        0           0   \n",
              "4              0             0               0       0        0           0   \n",
              "\n",
              "   Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡  Ø§Ø´ØªØºØ§Ù„  Ø­ÛŒÙˆØ§Ù†Ø§Øª Ø®Ø§Ù†Ú¯ÛŒ  \\\n",
              "0        0       0              0   \n",
              "1        0       0              0   \n",
              "2        0       0              0   \n",
              "3        0       0              0   \n",
              "4        0       0              0   \n",
              "\n",
              "                                             content  \n",
              "0   Ù…Ø¹Ù†ÛŒ Ø§Ø² Ø´ÙˆØ¨Ù†Ø¯Ù‡ Ù‡Ø§ | Ø¬Ø¯ÙˆÙ„ ÛŒØ§Ø¨- Ù…Ø¹Ù†ÛŒ Ø§Ø² Ø´ÙˆØ¨Ù†Ø¯Ù‡ ...  \n",
              "1  Ø¹Ú©Ø³ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„-Ø¹Ú©Ø³ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ú©Ø´ Ø¨...  \n",
              "2  Ø¯Ú©ØªØ± Ù…Ù‡Ù†Ø§Ø² Ø¹Ø§Ø¨Ø¯ÛŒÙ†ÛŒ Ù…ØªØ®ØµØµ Ø±Ø§Ø¯ÛŒÙˆÙ„ÙˆÚ˜ÛŒ Ùˆ Ø³ÙˆÙ†ÙˆÚ¯Ø±Ø§ÙÛŒ...  \n",
              "3  Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ­Ø±ÛŒÙ…â€ŒÚ¯Ø°Ø± Geph Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯-Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ­Ø±ÛŒ...  \n",
              "4  ØªØ±ÙÙ†Ø¯Ù‡Ø§ÛŒ Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯ ØªÙ„ÙˆÛŒØ²ÛŒÙˆÙ†â€Œâ€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯...  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c94f3f1f-c13a-40e0-aee6-b13c6b289bf7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ú©ØªØ§Ø¨ Ùˆ Ø§Ø¯Ø¨ÛŒØ§Øª</th>\n",
              "      <th>ØªØ¬Ø§Ø±Øª Ùˆ Ø§Ù‚ØªØµØ§Ø¯</th>\n",
              "      <th>Ø³Ù„Ø§Ù…Øª</th>\n",
              "      <th>ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ùˆ Ú©Ø§Ù…Ù¾Ø¨ÙˆØªØ±</th>\n",
              "      <th>ÙˆØ±Ø²Ø´</th>\n",
              "      <th>ØºØ°Ø§ Ùˆ Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ</th>\n",
              "      <th>Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯ÙˆÙ„Øª Ùˆ Ø³ÛŒØ§Ø³Øª</th>\n",
              "      <th>Ù…Ø³Ú©Ù†</th>\n",
              "      <th>Ø®ÙˆØ¯Ø±Ùˆ</th>\n",
              "      <th>Ù…Ø¯ Ùˆ Ø²ÛŒØ¨Ø§ÛŒÛŒ</th>\n",
              "      <th>...</th>\n",
              "      <th>Ø³ÙØ± Ùˆ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ</th>\n",
              "      <th>Ù‡Ù†Ø± Ùˆ Ø³Ø±Ú¯Ø±Ù…ÛŒ</th>\n",
              "      <th>Ø®Ø§Ù†Ù‡ Ùˆ Ø¨Ø§ØºØ¨Ø§Ù†ÛŒ</th>\n",
              "      <th>Ù…ÙˆØ³ÛŒÙ‚ÛŒ</th>\n",
              "      <th>ØªØ­ØµÛŒÙ„Ø§Øª</th>\n",
              "      <th>Ø¹Ù„Ù… Ùˆ Ø¯Ø§Ù†Ø´</th>\n",
              "      <th>Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡</th>\n",
              "      <th>Ø§Ø´ØªØºØ§Ù„</th>\n",
              "      <th>Ø­ÛŒÙˆØ§Ù†Ø§Øª Ø®Ø§Ù†Ú¯ÛŒ</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Ù…Ø¹Ù†ÛŒ Ø§Ø² Ø´ÙˆØ¨Ù†Ø¯Ù‡ Ù‡Ø§ | Ø¬Ø¯ÙˆÙ„ ÛŒØ§Ø¨- Ù…Ø¹Ù†ÛŒ Ø§Ø² Ø´ÙˆØ¨Ù†Ø¯Ù‡ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Ø¹Ú©Ø³ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„-Ø¹Ú©Ø³ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ú©Ø´ Ø¨...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Ø¯Ú©ØªØ± Ù…Ù‡Ù†Ø§Ø² Ø¹Ø§Ø¨Ø¯ÛŒÙ†ÛŒ Ù…ØªØ®ØµØµ Ø±Ø§Ø¯ÛŒÙˆÙ„ÙˆÚ˜ÛŒ Ùˆ Ø³ÙˆÙ†ÙˆÚ¯Ø±Ø§ÙÛŒ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ­Ø±ÛŒÙ…â€ŒÚ¯Ø°Ø± Geph Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯-Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ­Ø±ÛŒ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ØªØ±ÙÙ†Ø¯Ù‡Ø§ÛŒ Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯ ØªÙ„ÙˆÛŒØ²ÛŒÙˆÙ†â€Œâ€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c94f3f1f-c13a-40e0-aee6-b13c6b289bf7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c94f3f1f-c13a-40e0-aee6-b13c6b289bf7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c94f3f1f-c13a-40e0-aee6-b13c6b289bf7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e63504b4-2dfa-47ed-b8a5-40d4026633ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e63504b4-2dfa-47ed-b8a5-40d4026633ee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e63504b4-2dfa-47ed-b8a5-40d4026633ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "proccessed_data"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = proccessed_data['content']\n",
        "\n",
        "target_list = proccessed_data.drop('content',axis=1)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    features, target_list, test_size=0.2, random_state=42, stratify=target_list\n",
        ")\n",
        "\n",
        "print(\"Training set shape:\", x_train.shape)\n",
        "print(\"Test set shape:\", x_test.shape)\n",
        "\n",
        "# print(\"Training set shape:\", y_train.shape)\n",
        "# print(\"Test set shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "-W7tmiKGCmsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f16a26b-a718-44d9-fe42-0f2cbbc8815a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (3831,)\n",
            "Test set shape: (958,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implement hypo parameters\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 1e-05"
      ],
      "metadata": {
        "id": "P_NufE1OFI0E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "sxSlM88qFdgD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [CLS] , [PAD] , [SEP] , [MASK]\n",
        "\n",
        "example_text = \"My name is hossein\"\n",
        "\n",
        "encodings = tokenizer.encode_plus(\n",
        "    example_text,\n",
        "    add_special_tokens=True,\n",
        "    max_length=MAX_LEN,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encodings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ0txiKwCmON",
        "outputId": "9a6e1628-4ab8-4cd4-9d83-4a9ad222e80a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2026,  2171,  2003,  7570, 11393,  2378,   102,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.title = df['content'].astype(str)\n",
        "         # Get all category columns (assuming they start with 'category_')\n",
        "        self.category_columns = [col for col in df.columns if col.startswith('category_')]\n",
        "        self.targets = df[self.category_columns].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(), # [1, 512] => [512]\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'token_type_ids': inputs['token_type_ids'].flatten(),\n",
        "            'targets': torch.FloatTensor(self.targets[index]),\n",
        "        }"
      ],
      "metadata": {
        "id": "EC5v99gPHLvl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.8\n",
        "\n",
        "print(x_train)\n",
        "\n",
        "train_df = pd.concat([x_train, y_train], axis=1)\n",
        "train_df = train_df.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "\n",
        "val_df = pd.concat([x_test, y_test], axis=1)\n",
        "val_df = val_df.drop(x_test.index).reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfCjIeG1HMe9",
        "outputId": "cffb4eb7-584e-4293-a969-57f19fe177be"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3380    Mamad ahmadi-Mamad ahmadi Skip to content Ø´Ø¨Ú©Ù‡...\n",
            "1457    Ø®ÙˆØ§Øµ Ø¹Ø§Ù‚Ø±Ù‚Ø±Ø­Ø§ Ø› Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¹Ø§Ù‚Ø±Ù‚Ø±Ø­Ø§ Ø¯Ø± Ø·Ø¨...\n",
            "1473    Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ú©ÙŠÙ‡Ø§Ù†:                                ...\n",
            "3316    Ø¢ØºØ§Ø² Ø«Ø¨Øª Ù†Ø§Ù… Ø·Ø±Ø­â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ÛŒØ±Ø§Ù†â€ŒØ®ÙˆØ¯Ø±Ùˆ-...\n",
            "148     ØªÙˆØ± Ø®Ø§Ø±Ø¬ÛŒ | ØªØ±Ú©ÛŒÙ‡ ğŸ•Œ ØŒ Ø§Ù…Ø§Ø±Ø§Øª ØŒ ØªØ§ÛŒÙ„Ù†Ø¯ ØŒ Ù…Ø§Ù„Ø²ÛŒ ...\n",
            "                              ...                        \n",
            "2861    Ø±ÙˆØ´ Ø¯Ø±Ø³Øª Ø¨Ø±Ø®ÙˆØ±Ø¯ Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ù‡Ù…Ø³Ø± Ú†ÛŒØ³ØªØŸ-Ø±ÙˆØ´ Ø¯Ø±Ø³Øª ...\n",
            "3314    ÛŒØ§Ø³Ù…ÛŒÙ† Ù…Ù‚Ø¨Ù„ÛŒØŒ Ø²Ù† Ø§ÛŒØ±Ø§Ù†ÛŒ Ú©Ù‡ Ø¨Ù‡ Ù…Ø§Ù‡ Ù…ÛŒâ€ŒØ±ÙˆØ¯ - Ø¨Ù‡Ø§...\n",
            "4104    Ø¨Ø°Ø± Ú©Ø§Ú©ØªÙˆØ³ Ù‡Ø§ÛŒ Ø³ØªÙˆÙ†ÛŒ Ù…ÛŒÚ©Ø³ Ø¨Ø³ØªÙ‡ Û±Û° Ø¹Ø¯Ø¯ÛŒ - Ù…ÛŒÙ‡Ù† ...\n",
            "4519    Ø®Ø±ÛŒØ¯ Ùˆ Ù‚ÛŒÙ…Øª Ú©ØªØ§Ø¨ Ù‚ØµÙ‡ Ù‡Ø§ Ùˆ ØºØµÙ‡ Ù‡Ø§ÛŒ Ø²Ø§Ù„ Ø²Ø± Ø§Ø«Ø± Ø¹...\n",
            "3832    Ù…Ø§Ù‡Ù†Ø§Ù…Ù‡ Ø´Ù…Ø§Ø±Û€ 50 Ùˆ 51 Ù¾ÛŒØ´ Ø¨Ù‡ Ø³ÙˆÛŒ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø§Ù‚ØªØµØ§...\n",
            "Name: content, Length: 3831, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_df,tokenizer,MAX_LEN)\n",
        "valid_dataset = CustomDataset(val_df,tokenizer,MAX_LEN)"
      ],
      "metadata": {
        "id": "lTWYdjwgHMvR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=VALID_BATCH_SIZE,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "TWCCpikzPMD3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap7S2rqEPuHX",
        "outputId": "f4eb92da-2b1d-49d7-9204-608cd08faa22"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath,model,optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    return model, optimizer, checkpoint['epoch'],valid_loss_min.item()\n",
        "\n",
        "\n",
        "def save_ckp(state,is_best,checkpoint_path,best_model_path):\n",
        "    f_path = checkpoint_path\n",
        "    torch.save(state,f_path)\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        shutil.copyfile(f_path,best_fpath)"
      ],
      "metadata": {
        "id": "fmXksHwPP_pf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased',return_dict=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.linear = nn.Linear(768,6)\n",
        "\n",
        "    def forward(self,input_ids,attention_mask,token_type_ids):\n",
        "      output = self.bert_model(input_ids,attention_mask,token_type_ids)\n",
        "      output_dropout = self.dropout(output.pooler_output)\n",
        "      output = self.linear(output_dropout)\n",
        "      return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830,
          "referenced_widgets": [
            "dae0fac7695f4d36a1e4094a2b7e7c1d",
            "62196b9a513244beaa359f9b2152067e",
            "7ae2430787b44f54b2ce92ab4f9ccde2",
            "5d0718d6031c4cbdb1a2c6f4dd1a7df7",
            "2a7b590fadde4a58808b27b0beb13d67",
            "173be3a187364bf3889314ce1fb0259b",
            "2da30632a17f4d4a8c5998f52fe51fe3",
            "7fbdfec48171456aa0ea1cb006d867b4",
            "e915d71fc75c40dc8e71c92af60c8d14",
            "0b1cd6219e7341baa38e12e0d959bec1",
            "04a3392ec41b497b91bdc48fdda7fc20"
          ]
        },
        "id": "kz8aDCaSRf3e",
        "outputId": "81d19f78-2523-4ee9-e87d-602e53da146a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae0fac7695f4d36a1e4094a2b7e7c1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs,targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "kWjYClrij1Wy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    n_epochs,\n",
        "    training_loader,\n",
        "    validation_loader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    checkpoint_path,\n",
        "    best_model_path\n",
        "):\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        # training loop\n",
        "        for index, batch in enumerate(training_loader):\n",
        "            input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "            attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = batch['targets'].to(device, dtype=torch.float)\n",
        "            outputs = model(input_ids,attention_mask,token_type_ids)\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + (1/(index+1) (loss.item() - train_loss))\n",
        "\n",
        "        # validation loop\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "             for index, batch in enumerate(validation_loader):\n",
        "                 input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "                 attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "                 token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "                 targets = batch['targets'].to(device, dtype=torch.float)\n",
        "                 outputs = model(input_ids,attention_mask,token_type_ids)\n",
        "                 optimizer.zero_grad()\n",
        "                 loss = loss_fn(outputs, targets)\n",
        "                 optimizer.step()\n",
        "                 val_loss = valid_loss + (1/(index+1) (loss.item() - valid_loss))\n",
        "\n",
        "        checkpoint = {\n",
        "             'epoch' : epoch+1,\n",
        "             'valid_loss_min': valid_loss,\n",
        "             'state_dict': model.state_dict(),\n",
        "             'optimizer': optimizer.state_dict()\n",
        "            }\n",
        "\n",
        "        save_ckp(checkpoint,False,checkpoint_path,best_model_path)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "B8WHiHMdlz80"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, \"/curr_ckpt\",\"/best.pt\")"
      ],
      "metadata": {
        "id": "HE8b07WknEIA",
        "outputId": "ffa7f60b-49d8-4b87-be4b-78f35d1b2c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Target size (torch.Size([32, 0])) must be the same as input size (torch.Size([32, 6]))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-ff1441571677>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/curr_ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-a5fb38435b66>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(n_epochs, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-c9f84bdf8b0f>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         return F.binary_cross_entropy_with_logits(\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32, 0])) must be the same as input size (torch.Size([32, 6]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = x_test.iloc[300]\n",
        "print(example)\n",
        "\n",
        "encodings = tokenizer.encode_plus(\n",
        "    example,\n",
        "    None,\n",
        "    add_special_tokens=True,\n",
        "    max_length=MAX_LEN,\n",
        "    padding='max_length',\n",
        "    return_token_type_ids=True,\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "     input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n",
        "     attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n",
        "     token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n",
        "     output = model(input_ids,attention_mask,token_type_ids)\n",
        "     final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n",
        "     print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])"
      ],
      "metadata": {
        "id": "7h6xwo6zr4Ii",
        "outputId": "eae30484-ac7c-4663-fed1-5f70522676c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ù‡Ù†Ø±Ø³ØªØ§Ù† Ù¾Ø³Ø±Ø§Ù†Ù‡ Ø´Ù‡ÛŒØ¯Ù…ÙØªØ­ Ø¯Ù…Ø§ÙˆÙ†Ø¯-Ù‡Ù†Ø±Ø³ØªØ§Ù† Ù¾Ø³Ø±Ø§Ù†Ù‡ Ø´Ù‡ÛŒØ¯Ù…ÙØªØ­ Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ø¯Ø§Ù†Ø´â€ŒÙ†Ø§Ù…Ù‡ Ù…Ø¯Ø§Ø±Ø³ Ø¨Ø±Ú¯ Ù†Ø®Ø³Øª Ø§Ø³ØªØ§Ù† Ù…Ø¯Ø±Ø³Ù‡ Ø¯ÙˆÙ„ØªÛŒ Ù¾Ø³Ø±Ø§Ù†Ù‡ Ø´Ù‡ÛŒØ¯Ù…ÙØªØ­ (Ø¯Ù…Ø§ÙˆÙ†Ø¯) Ø¯Ø± Ù…Ù‚Ø·Ø¹ Ú©Ø§Ø±Ø¯Ø§Ù†Ø´ Ø´Ø§Ù…Ù„ Ø±Ø´ØªÙ‡ Ù‡Ø§ÛŒ Ø¨Ø±Ù‚ Ø³Ø§Ø®ØªÙ…Ø§Ù†ØŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†ØªØ±Ù†ØªÛŒ Ùˆ Ø·Ø±Ø§Ø­ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡â€ŒÛŒ ØµÙØ­Ø§Øª ÙˆØ¨ Ø´Ù‡Ø±ÛŒ Ø´Ø¨Ø§Ù†Ù‡â€ŒØ±ÙˆØ²ÛŒ ØªÙ…Ø§Ø³ Ù‡Ù…â€ŒØ±Ø³Ø§Ù†ÛŒ Ù…Ø¹Ø±ÙÛŒ Ù‡Ù†Ø±Ø³ØªØ§Ù† Ù¾Ø³Ø±Ø§Ù†Ù‡ Ø´Ù‡ÛŒØ¯Ù…ÙØªØ­ Ø§Ø² Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ø§Ø±Ø³ Ø¯ÙˆÙ„ØªÛŒ ÙˆØ§Ù‚Ø¹ Ø¯Ø± Ø´Ù‡Ø± Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ø§Ø³ØªØ§Ù† ØªÙ‡Ø±Ø§Ù† Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯. Ø§ÛŒÙ† Ù…Ø±Ú©Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ú©Ø§Ø±Ø¯Ø§Ù†Ø´ Ø¯Ø± Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§â€ŒÛŒ Ø¨Ø±Ù‚ Ø³Ø§Ø®ØªÙ…Ø§Ù†ØŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†ØªØ±Ù†ØªÛŒ Ùˆ Ø·Ø±Ø§Ø­ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡â€ŒÛŒ ØµÙØ­Ø§Øª ÙˆØ¨ØŒ Ø®Ø¯Ù…Ø§Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒÙ†Ù…Ø§ÛŒØ¯. Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø±Ø§ Ø³Ø¹ÛŒØ¯ Ù„Ø·ÛŒÙÛŒ Ø¨Ø± Ø¹Ù‡Ø¯Ù‡ Ø¯Ø§Ø±Ø¯. Ø§ÙˆÙ„ÛŒØ§ÛŒ Ú¯Ø±Ø§Ù…ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¬Ù‡Øª Ù…Ø´Ø§ÙˆØ±Ù‡ Ùˆ Ù†ÛŒØ² Ø§Ù†Ø¬Ø§Ù… Ø§Ù…ÙˆØ± Ø«Ø¨Øªâ€Œ Ù†Ø§Ù… Ø¨Ù‡ ØµÙˆØ±Øª Ø­Ø¶ÙˆØ±ÛŒ Ø¨Ø§ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ø¨Ù‡ Ù†Ø´Ø§Ù†ÛŒ Ú©ÛŒÙ„Ø§Ù† Ú©ÙˆÙ‡Ø§Ù† Ø¬Ù†Ø¨ Ù¾Ù…Ù¾ Ú¯Ø§Ø²Ø› Ú©Ø¯Ù¾Ø³ØªÛŒ 3976113585 ÛŒØ§ ØºÛŒØ± Ø­Ø¶ÙˆØ±ÛŒ Ø§Ø² Ø·Ø±ÛŒÙ‚ ØªÙ…Ø§Ø³ ØªÙ„ÙÙ†ÛŒ Ø¨Ø§ 76362288 (Ù¾ÛŒØ´â€ŒØ´Ù…Ø§Ø±Ù‡: 021) Ø§Ù‚Ø¯Ø§Ù… ÙØ±Ù…Ø§ÛŒÙ†Ø¯. Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø±ÙØ§Ù‡ÛŒ Ø³Ø±ÙˆÛŒØ³ Ø§ÛŒØ§Ø¨ Ùˆ Ø°Ù‡Ø§Ø¨ Ø³Ø§Ù„Ù† ØºØ°Ø§Ø®ÙˆØ±ÛŒ Ø¨ÙˆÙÙ‡ Ú©Ù…Ø¯ Ø´Ø®ØµÛŒ Ø§ØªØ§Ù‚ Ø¨Ø§Ø²ÛŒ Ù†Ù…Ø§Ø²Ø®Ø§Ù†Ù‡ Ú†Ù…Ù† Ù…ØµÙ†ÙˆØ¹ÛŒ Ø³Ø§Ø®ØªÙ…Ø§Ù† Ù…Ø³Ø§Ø­Øª Ø²Ù…ÛŒÙ† Ù…Ø³Ø§Ø­Øª Ø¨Ù†Ø§ ØªØ¹Ø¯Ø§Ø¯ Ø·Ø¨Ù‚Ù‡ Ø³Ø§Ù„ Ø³Ø§Ø®Øª ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ø§Ø³ Ù†Ù…Ø§ ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø«Ø¨Øª ØªØ±Ø¯Ø¯ ØªØ®ØªÙ‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙˆÛŒØ¯Ø¦Ùˆ Ù¾Ø±ÙˆÚ˜Ú©ØªÙˆØ± ÛŒÙˆ Ù¾ÛŒ Ø§Ø³ Ú˜Ù†Ø±Ø§ØªÙˆØ± Ø®Ø¯Ù…Ø§Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ù…Ø³ØªÙ…Ø± Ù…Ø´Ø§ÙˆØ±Ø§Ù† Ø¨Ø§ Ø§ÙˆÙ„ÛŒØ§ ØªÙ†Ø¸ÛŒÙ… Ùˆ Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ø·Ø±Ø­ Ø¯Ø±Ø³ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÛŒ ØªØ­ØµÛŒÙ„ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ‚ÙˆÛŒØª ØªÙˆØ§Ù†Ù…Ù†Ø¯ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† ØªØ´Ú©ÛŒÙ„ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ø¬Ù‡Øª Ø´Ø±Ú©Øª Ø¯Ø± Ø§Ù„Ù…Ù¾ÛŒØ§Ø¯ Ø¢Ù…ÙˆØ²Ø´ Ø²Ø¨Ø§Ù† Ø¯ÙˆÙ… Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¯Ø±Ø³ÛŒ Ù…Ø®ØªØµ Ù‡Ø± Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ² Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ú©Ø§Ø±Ù†Ø§Ù…Ù‡â€ŒÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªØ­ØµÛŒÙ„ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ù„Ù…Ø§Ù† Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¢Ø²Ù…ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ú©Ø´ÙˆØ±ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ´ Ø¯Ø±Ø³Øª ØªØ³Øªâ€ŒØ²Ù†ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ø¯ÙØ§ØªØ± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¨Ù‡Ø±Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù†ÙˆÛŒÙ† Ø¯Ø± Ø­ÙˆØ²Ù‡â€ŒÛŒ ØªØ¯Ø±ÛŒØ³ Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ø´ÛŒÙ…ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ ÙÛŒØ²ÛŒÚ© Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ø²ÛŒØ³Øª Ø´Ù†Ø§Ø³ÛŒ Ú©Ø§Ø±Ú¯Ø§Ù‡ Ø±Ø§ÛŒØ§Ù†Ù‡ Ú©Ø§Ø±Ú¯Ø§Ù‡ Ø­Ø±ÙÙ‡ Ùˆ ÙÙ† Ú©Ø§Ø±Ú¯Ø§Ù‡ Ù‡Ù†Ø±Ù‡Ø§ÛŒ ØªØ¬Ø³Ù…ÛŒ Ø³Ø§Ù„Ù† Ù…Ø·Ø§Ù„Ø¹Ù‡ ÙˆØ§Ø­Ø¯ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø§Ù…Ú©Ø§Ù†Ø§Øª ÙØ±Ø§Ø¢Ù…ÙˆØ²Ø´ÛŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø³Ø§Ù„Ù† Ù‡Ù…Ø§ÛŒØ´ ÛŒØ§ Ø¢Ù…ÙÛŒ ØªØ¦Ø§ØªØ± Ø³Ù…Ø¹ÛŒ Ùˆ Ø¨ØµØ±ÛŒ Ø³Ø§Ù„Ù† ÙˆØ±Ø²Ø´ Ø§Ø³ØªØ®Ø± Ø¨Ø³Ú©ØªØ¨Ø§Ù„ Ù‡Ù†Ø¯Ø¨Ø§Ù„ ØªÙ†ÛŒØ³ Ø¨Ø¯Ù…ÛŒÙ†ØªÙˆÙ† Ø§ØªØ§Ù‚ Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¢Ú©Ø§Ø¯Ù…ÛŒ Ø²Ø¨Ø§Ù† Ø®Ø¯Ù…Ø§Øª ÙØ±Ø§Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù…Ø¹Ø§ÛŒÙ†Ø§Øª Ù…Ø³ØªÙ…Ø± Ù¾Ø²Ø´Ú©ÛŒ Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ ÙˆØ±Ø²Ø´ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ´Ù†ÙˆÛŒØ³ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø±Ø¨Ø§ØªÛŒÚ© Ùˆ Ù„Ú¯Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù‚Ø±Ø¢Ù† Ø¢Ù…ÙˆØ²Ø´ ØªØ¦Ø§ØªØ± Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ÛŒØ§Ù†Ù‡ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø§Ø±Ø¯ÙˆÙ‡Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ Ùˆ Ø¹Ù„Ù…ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø§Ø±Ø¯ÙˆÙ‡Ø§ÛŒ ØªÙØ±ÛŒØ­ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨â€ŒÙ‡Ø§ Ùˆ Ø¬Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù„ÛŒ Ùˆ Ù…Ø°Ù‡Ø¨ÛŒ Ø§Ù…Ú©Ø§Ù† Ø®Ø±ÛŒØ¯ ÛŒØ§ Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ú©ØªØ§Ø¨ Ø´Ø±Ú©Øª Ø¯Ø± Ù…Ø³Ø§Ø¨Ù‚Ø§Øª ÙˆØ±Ø²Ø´ÛŒ Ø´Ø±Ú©Øª Ø¯Ø± Ù…Ø³Ø§Ø¨Ù‚Ø§Øª ÙØ±Ù‡Ù†Ú¯ÛŒ Ùˆ Ù‡Ù†Ø±ÛŒ Ø´Ø±Ú©Øª Ø¯Ø± Ù…Ø³Ø§Ø¨Ù‚Ø§Øª Ø¹Ù„Ù…ÛŒ Ø¢Ø¦ÛŒÙ†â€ŒÙ†Ø§Ù…Ù‡â€ŒÛŒ Ø§Ù†Ø¶Ø¨Ø§Ø·ÛŒ ØªÙ…Ø§Ø³ Ù¾ÛŒØ´â€ŒØ´Ù…Ø§Ø±Ù‡: 021 ØªÙ„ÙÙ†: 76362288 Ù†Ù…Ø§Ø¨Ø±: Ø§ÛŒÙ…ÛŒÙ„: Ø§Ø³ØªØ§Ù†: ØªÙ‡Ø±Ø§Ù† Ø´Ù‡Ø±: Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ù…Ù†Ø·Ù‚Ù‡: Ù…Ø­Ù„Ù‡: Ù†Ø´Ø§Ù†ÛŒ: Ú©ÛŒÙ„Ø§Ù† Ú©ÙˆÙ‡Ø§Ù† Ø¬Ù†Ø¨ Ù¾Ù…Ù¾ Ú¯Ø§Ø² Ú©Ø¯Ù¾Ø³ØªÛŒ: 3976113585 ÙˆØ¨â€ŒÚ¯Ø§Ù‡: ØªÙˆÛŒÛŒØªØ±: ØªÙ„Ú¯Ø±Ø§Ù…: ÙÛŒØ³Ø¨ÙˆÚ©: Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…: Ø¢Ù¾Ø§Ø±Ø§Øª: Ù…Ø¯ÛŒØ±Ø§Ù†ØŒ Ú©Ø§Ø±Ú©Ù†Ø§Ù†ØŒ Ù…Ø¯Ø±Ø³Ø§Ù† Ùˆ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§ Ø§ØµÙ„Ø§Ø­ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ùˆ ØªØµØ§ÙˆÛŒØ± Ø§ÛŒÙ† Ù…Ø¯Ø±Ø³Ù‡ Ø§Ù‚Ø¯Ø§Ù… Ù†Ù…Ø§ÛŒÙ†Ø¯. b xpx # / b xpx b # / b Ø§ÙØ²ÙˆØ¯Ù† b Ø³Ø§Ù„ / Ù…Ø§Ù‡ / Ø±ÙˆØ² Ø³Ø§Ø¹Øª : Ø¯Ù‚ÛŒÙ‚Ù‡ Ã— Ã— Â©2022 School Encyclopedia. All rights reserved. Ù‡Ù…â€ŒØ±Ø³Ø§Ù†ÛŒ Ù…Ø¹Ø±ÙÛŒ Ù‡Ù†Ø±Ø³ØªØ§Ù† Ù¾Ø³Ø±Ø§Ù†Ù‡ Ø´Ù‡ÛŒØ¯Ù…ÙØªØ­ Ø§Ø² Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ø§Ø±Ø³ Ø¯ÙˆÙ„ØªÛŒ ÙˆØ§Ù‚Ø¹ Ø¯Ø± Ø´Ù‡Ø± Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ø§Ø³ØªØ§Ù† ØªÙ‡Ø±Ø§Ù† Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯. Ø§ÛŒÙ† Ù…Ø±Ú©Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ú©Ø§Ø±Ø¯Ø§Ù†Ø´ Ø¯Ø± Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§â€ŒÛŒ Ø¨Ø±Ù‚ Ø³Ø§Ø®ØªÙ…Ø§Ù†ØŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†ØªØ±Ù†ØªÛŒ Ùˆ Ø·Ø±Ø§Ø­ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡â€ŒÛŒ ØµÙØ­Ø§Øª ÙˆØ¨ØŒ Ø®Ø¯Ù…Ø§Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒÙ†Ù…Ø§ÛŒØ¯. Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø±Ø§ Ø³Ø¹ÛŒØ¯ Ù„Ø·ÛŒÙÛŒ Ø¨Ø± Ø¹Ù‡Ø¯Ù‡ Ø¯Ø§Ø±Ø¯. Ø§ÙˆÙ„ÛŒØ§ÛŒ Ú¯Ø±Ø§Ù…ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¬Ù‡Øª Ù…Ø´Ø§ÙˆØ±Ù‡ Ùˆ Ù†ÛŒØ² Ø§Ù†Ø¬Ø§Ù… Ø§Ù…ÙˆØ± Ø«Ø¨Øªâ€Œ Ù†Ø§Ù… Ø¨Ù‡ ØµÙˆØ±Øª Ø­Ø¶ÙˆØ±ÛŒ Ø¨Ø§ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ø¨Ù‡ Ù†Ø´Ø§Ù†ÛŒ Ú©ÛŒÙ„Ø§Ù† Ú©ÙˆÙ‡Ø§Ù† Ø¬Ù†Ø¨ Ù¾Ù…Ù¾ Ú¯Ø§Ø²Ø› Ú©Ø¯Ù¾Ø³ØªÛŒ 3976113585 ÛŒØ§ ØºÛŒØ± Ø­Ø¶ÙˆØ±ÛŒ Ø§Ø² Ø·Ø±ÛŒÙ‚ ØªÙ…Ø§Ø³ ØªÙ„ÙÙ†ÛŒ Ø¨Ø§ 76362288 (Ù¾ÛŒØ´â€ŒØ´Ù…Ø§Ø±Ù‡: 021) Ø§Ù‚Ø¯Ø§Ù… ÙØ±Ù…Ø§ÛŒÙ†Ø¯. Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø±ÙØ§Ù‡ÛŒ Ø³Ø±ÙˆÛŒØ³ Ø§ÛŒØ§Ø¨ Ùˆ Ø°Ù‡Ø§Ø¨ Ø³Ø§Ù„Ù† ØºØ°Ø§Ø®ÙˆØ±ÛŒ Ø¨ÙˆÙÙ‡ Ú©Ù…Ø¯ Ø´Ø®ØµÛŒ Ø§ØªØ§Ù‚ Ø¨Ø§Ø²ÛŒ Ù†Ù…Ø§Ø²Ø®Ø§Ù†Ù‡ Ú†Ù…Ù† Ù…ØµÙ†ÙˆØ¹ÛŒ Ø³Ø§Ø®ØªÙ…Ø§Ù† Ù…Ø³Ø§Ø­Øª Ø²Ù…ÛŒÙ† Ù…Ø³Ø§Ø­Øª Ø¨Ù†Ø§ ØªØ¹Ø¯Ø§Ø¯ Ø·Ø¨Ù‚Ù‡ Ø³Ø§Ù„ Ø³Ø§Ø®Øª ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ø§Ø³ Ù†Ù…Ø§ ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø«Ø¨Øª ØªØ±Ø¯Ø¯ ØªØ®ØªÙ‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙˆÛŒØ¯Ø¦Ùˆ Ù¾Ø±ÙˆÚ˜Ú©ØªÙˆØ± ÛŒÙˆ Ù¾ÛŒ Ø§Ø³ Ú˜Ù†Ø±Ø§ØªÙˆØ± Ø®Ø¯Ù…Ø§Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ù…Ø³ØªÙ…Ø± Ù…Ø´Ø§ÙˆØ±Ø§Ù† Ø¨Ø§ Ø§ÙˆÙ„ÛŒØ§ ØªÙ†Ø¸ÛŒÙ… Ùˆ Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ø·Ø±Ø­ Ø¯Ø±Ø³ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÛŒ ØªØ­ØµÛŒÙ„ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ‚ÙˆÛŒØª ØªÙˆØ§Ù†Ù…Ù†Ø¯ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† ØªØ´Ú©ÛŒÙ„ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ø¬Ù‡Øª Ø´Ø±Ú©Øª Ø¯Ø± Ø§Ù„Ù…Ù¾ÛŒØ§Ø¯ Ø¢Ù…ÙˆØ²Ø´ Ø²Ø¨Ø§Ù† Ø¯ÙˆÙ… Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¯Ø±Ø³ÛŒ Ù…Ø®ØªØµ Ù‡Ø± Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ² Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ú©Ø§Ø±Ù†Ø§Ù…Ù‡â€ŒÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªØ­ØµÛŒÙ„ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ù„Ù…Ø§Ù† Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø¢Ø²Ù…ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ú©Ø´ÙˆØ±ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ´ Ø¯Ø±Ø³Øª ØªØ³Øªâ€ŒØ²Ù†ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ø¯ÙØ§ØªØ± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¨Ù‡Ø±Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù†ÙˆÛŒÙ† Ø¯Ø± Ø­ÙˆØ²Ù‡â€ŒÛŒ ØªØ¯Ø±ÛŒØ³ Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ø´ÛŒÙ…ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ ÙÛŒØ²ÛŒÚ© Ø¢Ø²Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ø²ÛŒØ³Øª Ø´Ù†Ø§Ø³ÛŒ Ú©Ø§Ø±Ú¯Ø§Ù‡ Ø±Ø§ÛŒØ§Ù†Ù‡ Ú©Ø§Ø±Ú¯Ø§Ù‡ Ø­Ø±ÙÙ‡ Ùˆ ÙÙ† Ú©Ø§Ø±Ú¯Ø§Ù‡ Ù‡Ù†Ø±Ù‡Ø§ÛŒ ØªØ¬Ø³Ù…ÛŒ Ø³Ø§Ù„Ù† Ù…Ø·Ø§Ù„Ø¹Ù‡ ÙˆØ§Ø­Ø¯ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø§Ù…Ú©Ø§Ù†Ø§Øª ÙØ±Ø§Ø¢Ù…ÙˆØ²Ø´ÛŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø³Ø§Ù„Ù† Ù‡Ù…Ø§ÛŒØ´ ÛŒØ§ Ø¢Ù…ÙÛŒ ØªØ¦Ø§ØªØ± Ø³Ù…Ø¹ÛŒ Ùˆ Ø¨ØµØ±ÛŒ Ø³Ø§Ù„Ù† ÙˆØ±Ø²Ø´ Ø§Ø³ØªØ®Ø± Ø¨Ø³Ú©ØªØ¨Ø§Ù„ Ù‡Ù†Ø¯Ø¨Ø§Ù„ ØªÙ†ÛŒØ³ Ø¨Ø¯Ù…ÛŒÙ†ØªÙˆÙ† Ø§ØªØ§Ù‚ Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¢Ú©Ø§Ø¯Ù…ÛŒ Ø²Ø¨Ø§Ù† Ø®Ø¯Ù…Ø§Øª ÙØ±Ø§Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù…Ø¹Ø§ÛŒÙ†Ø§Øª Ù…Ø³ØªÙ…Ø± Ù¾Ø²Ø´Ú©ÛŒ Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ ÙˆØ±Ø²Ø´ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ´Ù†ÙˆÛŒØ³ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø±Ø¨Ø§ØªÛŒÚ© Ùˆ Ù„Ú¯Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù‚Ø±Ø¢Ù† Ø¢Ù…ÙˆØ²Ø´ ØªØ¦Ø§ØªØ± Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ÛŒØ§Ù†Ù‡ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø§Ø±Ø¯ÙˆÙ‡Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ Ùˆ Ø¹Ù„Ù…ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ø§Ø±Ø¯ÙˆÙ‡Ø§ÛŒ ØªÙØ±ÛŒØ­ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨â€ŒÙ‡Ø§ Ùˆ Ø¬Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù„ÛŒ Ùˆ Ù…Ø°Ù‡Ø¨ÛŒ Ø§Ù…Ú©Ø§Ù† Ø®Ø±ÛŒØ¯ ÛŒØ§ Ø§Ø±Ø§Ø¦Ù‡â€ŒÛŒ Ú©ØªØ§Ø¨ Ø´Ø±Ú©Øª Ø¯Ø± Ù…Ø³Ø§Ø¨Ù‚Ø§Øª ÙˆØ±Ø²Ø´ÛŒ Ø´Ø±Ú©Øª Ø¯Ø± Ù…Ø³Ø§Ø¨Ù‚Ø§Øª ÙØ±Ù‡Ù†Ú¯ÛŒ Ùˆ Ù‡Ù†Ø±ÛŒ Ø´Ø±Ú©Øª Ø¯Ø± Ù…Ø³Ø§Ø¨Ù‚Ø§Øª Ø¹Ù„Ù…ÛŒ Ø¢Ø¦ÛŒÙ†â€ŒÙ†Ø§Ù…Ù‡â€ŒÛŒ Ø§Ù†Ø¶Ø¨Ø§Ø·ÛŒ ØªÙ…Ø§Ø³ Ù¾ÛŒØ´â€ŒØ´Ù…Ø§Ø±Ù‡: 021 ØªÙ„ÙÙ†: 76362288 Ù†Ù…Ø§Ø¨Ø±: Ø§ÛŒÙ…ÛŒÙ„: Ø§Ø³ØªØ§Ù†: ØªÙ‡Ø±Ø§Ù† Ø´Ù‡Ø±: Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ù…Ù†Ø·Ù‚Ù‡: Ù…Ø­Ù„Ù‡: Ù†Ø´Ø§Ù†ÛŒ: Ú©ÛŒÙ„Ø§Ù† Ú©ÙˆÙ‡Ø§Ù† Ø¬Ù†Ø¨ Ù¾Ù…Ù¾ Ú¯Ø§Ø² Ú©Ø¯Ù¾Ø³ØªÛŒ: 3976113585 ÙˆØ¨â€ŒÚ¯Ø§Ù‡: ØªÙˆÛŒÛŒØªØ±: ØªÙ„Ú¯Ø±Ø§Ù…: ÙÛŒØ³Ø¨ÙˆÚ©: Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…: Ø¢Ù¾Ø§Ø±Ø§Øª: Ù…Ø¯ÛŒØ±Ø§Ù†ØŒ Ú©Ø§Ø±Ú©Ù†Ø§Ù†ØŒ Ù…Ø¯Ø±Ø³Ø§Ù† Ùˆ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø§ÙØ²ÙˆØ¯Ù† ÛŒØ§ Ø§ØµÙ„Ø§Ø­ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ùˆ ØªØµØ§ÙˆÛŒØ± Ø§ÛŒÙ† Ù…Ø¯Ø±Ø³Ù‡ Ø§Ù‚Ø¯Ø§Ù… Ù†Ù…Ø§ÛŒÙ†Ø¯.-Ù‡Ù†Ø±Ø³ØªØ§Ù† Ø¯ÙˆÙ„ØªÛŒ Ù¾Ø³Ø±Ø§Ù†Ù‡ Ø´Ù‡ÛŒØ¯Ù…ÙØªØ­ Ø§Ø² Ù…Ø¯Ø§Ø±Ø³ Ø´Ù‡Ø± Ø¯Ù…Ø§ÙˆÙ†Ø¯ Ø§Ø³ØªØ§Ù† ØªÙ‡Ø±Ø§Ù† Ø¯Ø± Ù…Ù‚Ø·Ø¹ Ú©Ø§Ø±Ø¯Ø§Ù†Ø´ Ø§Ø³Øª.\n",
            "ÙˆØ±Ø²Ø´\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-92be12ea825a>:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(train_df.columns[1:].to_list()[int(np.argmax(final_output, axis=1))])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dae0fac7695f4d36a1e4094a2b7e7c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62196b9a513244beaa359f9b2152067e",
              "IPY_MODEL_7ae2430787b44f54b2ce92ab4f9ccde2",
              "IPY_MODEL_5d0718d6031c4cbdb1a2c6f4dd1a7df7"
            ],
            "layout": "IPY_MODEL_2a7b590fadde4a58808b27b0beb13d67"
          }
        },
        "62196b9a513244beaa359f9b2152067e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_173be3a187364bf3889314ce1fb0259b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2da30632a17f4d4a8c5998f52fe51fe3",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "7ae2430787b44f54b2ce92ab4f9ccde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fbdfec48171456aa0ea1cb006d867b4",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e915d71fc75c40dc8e71c92af60c8d14",
            "value": 440449768
          }
        },
        "5d0718d6031c4cbdb1a2c6f4dd1a7df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b1cd6219e7341baa38e12e0d959bec1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_04a3392ec41b497b91bdc48fdda7fc20",
            "value": "â€‡440M/440Mâ€‡[00:02&lt;00:00,â€‡250MB/s]"
          }
        },
        "2a7b590fadde4a58808b27b0beb13d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173be3a187364bf3889314ce1fb0259b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da30632a17f4d4a8c5998f52fe51fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fbdfec48171456aa0ea1cb006d867b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e915d71fc75c40dc8e71c92af60c8d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b1cd6219e7341baa38e12e0d959bec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a3392ec41b497b91bdc48fdda7fc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}